{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking and Visualizing fMRI data in 3D: Introduction to pycortex\t\n",
    "\n",
    "In this session, we will continue working on the material from last week and work with a visualization tool called [pycortex](https://gallantlab.org/pycortex/).\n",
    "\n",
    "# Goals\n",
    "* Understand the way pycortex represents a volumetric data set\n",
    "* Create pycortex Volume objects from 3D data, masked data, and time series data\n",
    "* Display data on the cortical surface\n",
    "\n",
    "## Short fMRI recap\n",
    "\n",
    "Things to remember:\n",
    "\n",
    " - The functional signal we measure with fMRI is *not* an electrical neural signal (as in EEG, ECoG, or electrophysiology). It is a magnetic signal related to the properties of brain tissue, and it is dominated by blood flow. \n",
    " - Blood flow is related to neural activity. \n",
    "     - Neural firing is metabolically demanding. \n",
    "     - Once region of the brain becomes active (once the neurons start firing), metabolism in that region is high and the neurons in that region need glucose. \n",
    "         - Glucose is not stored in the brain and needs to be transported to the active region whenever energy is needed. \n",
    "         - Glucose transported in red blood cells initiates a complex process to increase blood flow to the electrically active area bringing more oxygen into the region. \n",
    "         - When activity is high in a region oxygen gets stripped off of hemoglobin molecules in red blood cells (thereby changing the magnetic properties of hemoglobin, creating a deoxyhemoglobin). \n",
    " - There are several ways to measure functional responses with MRI, and the specific one that we work with is the Blood Oxygenation Level Dependent Response, or the BOLD response. \n",
    "\n",
    "\n",
    "## FMRI activity in time\n",
    "\n",
    "Once a neural event is triggered by a stimulus presentation the vascular system needs to respond to the need for glucose and oxygen in that specific brain area. This can take up to 1-2 seconds. Hence the hemodynamic response lags the triggered event by 1-2 seconds, which peaks around 5 seconds after the stimulus onset.\n",
    "\n",
    "![alt text](../../data/images/lagged_activity.png \"lagged_activity.png\")\n",
    "\n",
    "## Storing fMRI data for data analysis\n",
    "\n",
    "We store fMRI data as a matrix. This means that each volume (a timepoint) in the experiment will correspond to a row in the matrix, and each voxel will correspond to a column in that matrix. For this reason, we need to make sure the criteria we use to move each 3D image to a matrix row is preserved and this operation is inverted. Let's look at an example.\n",
    "\n",
    "![alt text](../../data/images/fmri_dimensions.png \"fmri_dimensions.png\")\n",
    "\n",
    "\n",
    "## Alignment\n",
    "fMRI measures activity across the whole brain (or large swathes of the brain), but it is difficult to map that activity to specific anatomical locations in the brain based on functional data alone. Many factors make anatomy ambiguous in functional data: **(1)** functional data are low resolution; **(2)** functional slices are not always aligned with the head in a consistent or precise way across subjects; and **(3)** there is considerable variation in anatomy (i.e., specific locations of sulci & gyri) across subjects. Thus, a common step in fMRI processing is to align the functional data with a high-resolution anatomical scan of the same subject. \n",
    "\n",
    "### Alignment in principle\n",
    "The scanner stores the location of the slices with respect to the magnet *isocenter* (the strongest point of the magnetic field in the MRI scanner; the center of the magnet). This data is transferred to the nifti files at file creation time. These transformations (from data space to scanner space) are still not enough to precisely align data from different anatomical and functional scans. The functional and anatomical data may have been collected on different days, or the subject may have shifted slightly between scans. Thus, the functional data needs to be moved and/or rotated in 3D to make sure it aligns as precisely as possible with the underlying anatomical data. \n",
    "\n",
    "\n",
    "![alt text](../../data/images/fMRI_Transforms.001.png \"fMRI_Transforms.001.png\")\n",
    "\n",
    "\n",
    "### Alignment in pycortex\n",
    "pycortex allows manual adjustment of the rotation & position of the functional data with respect to the 3D surface.\n",
    "\n",
    "![alt text](../../data/images/pycortex_aligner_transverse.png \"pycortex_aligner_transverse.png\")\n",
    "\n",
    "## Cortical surface extraction\n",
    "\n",
    "fMRI studies often focus on the cerebral cortex (the outermost layer of the brain). Consequently, it is common to display the results of statistical analyses of fMRI data on inflated and flattened representations of the cerebral cortex. Such cortical surface maps provide a way to examine all cortical fMRI data at once, with the anatomical location of the functional data made clear. \n",
    "\n",
    "The cortical surface must be computationally extracted from high spatial resolution anatomical MRI scans, and often manually edited (*NOTE: Manual editing to create a good corical surface can take days or weeks of effort! This data is not free!*)\n",
    "\n",
    "![alt text](../../data/images/MPRAGE.png \"MPRAGE.png\")\n",
    "\n",
    "![alt text](../../data/images/MPRAGE_wcortex.png \"MPRAGE_wcortex.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load some necessary libraries\n",
    "import os\n",
    "import nibabel  # Neuroimaging library to work with MR images\n",
    "import cortex  # This is our mapping software pycortex\n",
    "# import neurods # Our class module\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set matplotlib defaults\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "\n",
    "%matplotlib widget\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Same as previously: load using nibabel, use get_data() method of the nibabel data object, transpose resulting data array, and zscore the data. For now, we will treat this as a generic data set (next week, we will learn more about the experiment that generated this data as we begin to actually analyze the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../../data/fMRI/categories/s01_categories_01.nii.gz'\n",
    "nii = nibabel.load(fname) \n",
    "voldata = nii.get_fdata().T\n",
    "\n",
    "mask_fname = '../../data/fMRI/categories/s01_categories_mask_cortical.npz'\n",
    "mask = np.load(mask_fname)['mask']\n",
    "data = voldata[:, mask]\n",
    "data = zscore(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the first volume: (30, 100, 100)\n",
      "Dimensions of the data: (120, 38543)\n"
     ]
    }
   ],
   "source": [
    "first_volume = voldata[0]\n",
    "print(\"Dimensions of the first volume: {0}\".format(first_volume.shape))\n",
    "print(\"Dimensions of the data: {0}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is: (time, Z, Y, X). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onward to 3D data visualizations! \n",
    "\n",
    "We will use a python module called pycortex to show data in 3D on the brain. This module was developed here at UC Berkeley in the Gallant lab, mostly by James Gao, with help from Alex Huth, Mark Lescroart, and other lab members. The code is freely available online [here](https://github.com/gallantlab/pycortex), and a paper summarizing the code can be found [here](http://journal.frontiersin.org/article/10.3389/fninf.2015.00023/full). \n",
    "\n",
    "To map the functional data onto the cortex, pycortex requires at least two things:\n",
    "\n",
    "1. The cortical surface of the subject. \n",
    "    * pycortex stores cortical surface files (and several other files) for each subject in a reliably structured directory of files. Because of this reliable directory structure, all we need to provide to the code is a subject ID string, and the code will be able to find and load the relevant cortical surface files. \n",
    "2. The functional to anatomical aligmnent of this data to that cortical surface\n",
    "    * Alignment of functional data to anatomical data proceeds by an *affine transform*. How this transformation works is beyond the scope of this class, but you can look it up on [wikipedia](https://en.wikipedia.org/wiki/Affine_transformation) or in your favorite linear algebra textbook if you're curious. **[would be good to have some better references here]**. The practical upshot is that a 4x4 matrix of numbers is sufficient to store the 3 rotations (around the x, y, and z axes) and 3 the transformations (in the x, y and z dimensions) that will transform the functional data in space such that they are aligned with the anatomical data (with the cortical surface). In the pycortex code, \"transform\" is abbreviated in variable names as `xfm`. Just as with the cortical surface, we only need to specify a name for a transform, and the code will know where to find the file that contains the affine transformation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) subject (specifies the cortical surface of the brain)\n",
    "subject = 's01' \n",
    "# (2) transform \n",
    "transform = 'catloc' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display data in pycortex, we need to create a pycortex object that contains all the relevant information: the data, the cortical surface (i.e., the subject) and the affine transform. That object is called a Volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Volumetric data for (s01, catloc)>\n"
     ]
    }
   ],
   "source": [
    "# Create a volume\n",
    "data_volume = cortex.Volume(first_volume, subject, transform) \n",
    "print(data_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server on port 28338\n"
     ]
    }
   ],
   "source": [
    "# Show the volume in a 3D brain (ooooh)\n",
    "cortex.webgl.show(data_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> Explore the viewer! Play with buttons: flatten, color map, color limits, depth. \n",
    "\n",
    "Color maps are important! See [this blog post](http://bids.github.io/colormap/) by our local BIDS fellows on why you should be careful about selecting a color map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### TEACHER INFO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Show a flatmap inline\n",
    "# (If you get warnings about a module called shapely, ignore them; they are not important.)\n",
    "_ = cortex.quickflat.make_figure(data_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masks\n",
    "pycortex can be used to generate cortical masks; this is where the mask we used above came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mask = cortex.db.get_mask(subject, transform, type='cortical')\n",
    "first_volume_masked = voldata[0, mask]\n",
    "print('Shape of mask: ', mask.shape)\n",
    "print('Shape of masked data: ', first_volume_masked.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pycortex can also directly visualize masked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Show creation of volume from masked data\n",
    "print(data.shape)\n",
    "kwargs = dict(vmin=-3, vmax=3)\n",
    "vol = cortex.Volume(data[0], subject, transform, mask=mask, **kwargs)\n",
    "print(vol)\n",
    "print(vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Display this volume, too\n",
    "\n",
    "# Select other timepoints to display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### TEACHER INFO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a movie volume\n",
    "data_movie = cortex.Volume(data, subject, transform, mask=mask, vmin=-3, vmax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 3D web display takes a 4D volume, too\n",
    "cortex.webgl.show(data_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Breakout session\n",
    "> Find interesting time points in the experiment! Do different parts of the brain appear to be active at different times? Which parts? Try to create a mask that selects voxels in an interesting part of the brain based on the responses at particular points in the timecourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
